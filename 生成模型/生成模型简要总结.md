
## 什么是生成模型？

生成模型，顾名思义，从这个模型中可以生成新的数据，而我们研究生成模型的目的就是为了得到这样一个模型，从而使其可以产生我们所需要的新数据。为了得到这样的模型，我们需要更深入的探究这个**模型**的实质，我们假设已有的数据服从一个概率分布$p_{data}(x)$，我们获得新数据即是从这个分布当中取新的样本。在认识上面所述事实的条件下 ，我们的目的转变为了得到这样的一个分布$p_{data}(x)$，但是，直接获取这样的分布往往是一个很困难的事情，所以我们需要用一个分布$p_{model}(x)$去逼近这样的一个分布。我们研究生成模型就是为了获得这样的一个$p_{model}(x)$。

## 经典概率模型（简单了解）
### 高斯混合

#### 混合模型
混合模型是一个可以用来表示在总体分布（distribution）中含有 K 个子分布的概率模型，换句话说，混合模型表示了观测数据在总体中的概率分布，它是一个由 K 个子分布组成的混合分布。混合模型不要求观测数据提供关于子分布的信息，来计算观测数据在总体分布中的概率。
#### 高斯模型
##### 单高斯模型
当样本数据$X$是一维数据时，高斯分布遵循下面的概率密度函数
$$
P(x|\theta)=\frac{1}{\sqrt{2\pi\sigma^2}}exp(-\frac{(x-\mu)^2}{2\sigma^2})
$$
其中$\mu$是均值，$\sigma$是标准差

当样本数据$X$是多维数据时，高斯分布遵循下面的概率密度函数
$$
P(x|\theta) = \frac{1}{(2\pi)^{\frac{D}{2}} |\boldsymbol{\Sigma}|^{\frac{1}{2}}} 
\exp\left(
    -\frac{1}{2} (\mathbf{x} - \boldsymbol{\mu})^\top 
    \boldsymbol{\Sigma}^{-1} 
    (\mathbf{x} - \boldsymbol{\mu})
\right)
$$
其中$\Sigma$是协方差，$D$是数据维度

##### 混合模型

高斯混合模型可以看作是由K个单高斯模型组合而成的，这K个子模型可以看作是高斯混合模型的隐变量。

高斯混合模型的概率分布：
$$
P(x|\theta)=\Sigma_{k=1}^K\alpha_k\phi(x|\theta_k)
$$
其中：
$x_j$是观测数据
$K$是混合模型中子模型的数量
$\alpha_k$是观测数据属于第$k$个子模型的概率
$\phi(x|\theta_k)$是第$k$个子模型的概率密度函数

对于这个模型而言，参数就是每个子模型的期望、方差（或协方差）、在混合模型中发生的概率。

对于混合高斯模型可以使用$EM$算法求解其最大似然估计，见李航老师的机器学习方法，不多叙述。

#### 隐式马尔科夫模型

##### $n$阶马尔科夫过程
状态间的转移仅依赖前$n$个状态的过程就叫做$n$阶马尔科夫过程
$$
p(q_t=S_j|q_{t-1}=S_{i}, q_{t-2}=S_{i-1}, \cdots, q_{t-n}=S_{i-n+1})
$$
##### 隐式马尔科夫模型（HMM）

一个隐式马尔科夫模型一般记为$\lambda=[\pi, A, B]$,下面我们来解释一下这些符号的意义。

$\pi$是模型在初始状态下出现各状态的概率$\pi=(\pi_1, \cdots, \pi_n)$,$\pi_i$是初始状态是$S_i$的概率
$A$是各个状态直接转换的概率，通常记作矩阵$A[a_{ij}]$
$B$式根据当前状态获得各个观测值的概率，记作矩阵$B[b_{ij}]$

相对于马尔可夫模型，隐马尔可夫只是多了一个各状态的观测概率。
该模型是一个**双重随机过程**，包括**模型的状态转换**和**特定状态下可观察事件的随机**。


以上我们简单叙述了两种比较重要的机器学习生成预测模型，虽然这种模型本身已经被基于深度学习的很多方法超越，但是我认为在深度学习时代下，学习机器学习模型依旧是非常必要的。传统机器学习方法会教给我们很多思考方式，这种思考方式在很多时候可以帮助我们解决遇到的各种问题。

## 显式模型

### $\text{pixelRNN \& pixelCNN}$


